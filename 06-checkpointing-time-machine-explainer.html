<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Checkpointing: State Preservation for AI Training Workloads</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
:root {
    --primary-color: #00ACC1;
    --secondary-color: #26C6DA;
    --accent-color: #4DD0E1;
    --bg-color: #E0F7FA;
    --card-bg: #FFFFFF;
    --text-color: #1A1A1A;
    --border-color: #80DEEA;
    --shadow: 0 2px 8px rgba(0, 172, 193, 0.1);
}
body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
    background: var(--bg-color);
    color: var(--text-color);
    line-height: 1.6;
}
header {
    text-align: center;
    padding: 50px 40px;
    background: linear-gradient(135deg, #00ACC1, #26C6DA);
    color: white;
    position: relative;
}
header::before {
    content: '';
    position: absolute;
    font-size: 200px;
    opacity: 0.1;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    animation: rotate 10s linear infinite;
}
@keyframes rotate {
    from { transform: translate(-50%, -50%) rotate(0deg); }
    to { transform: translate(-50%, -50%) rotate(360deg); }
}
header h1 {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 12px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
}
.sidebar-wrapper {
    display: flex;
    min-height: calc(100vh - 200px);
}
.nav-menu {
    width: 280px;
    min-width: 280px;
    background: #80DEEA;
    border-right: 2px solid var(--border-color);
    padding: 20px 0;
    position: sticky;
    top: 0;
    height: calc(100vh - 200px);
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 4px;
}
.nav-link {
    color: var(--text-color);
    text-decoration: none;
    padding: 12px 20px;
    margin: 0 10px;
    border-radius: 6px;
    transition: all 0.2s ease;
    font-weight: 500;
    display: block;
}
.nav-link:hover, .nav-link.active {
    background: var(--primary-color);
    color: white;
}
.main-content-wrapper {
    flex: 1;
    width: calc(100% - 280px);
    min-width: 0;
}

.section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
.section h2 {
    font-size: 2.2rem;
    margin-bottom: 20px;
    color: var(--primary-color);
    border-bottom: 3px solid var(--primary-color);
    padding-bottom: 10px;
}
.time-card {
    background: var(--card-bg);
    padding: 25px;
    border-radius: 12px;
    border: 2px solid var(--border-color);
    margin: 20px 0;
    box-shadow: var(--shadow);
}
.mermaid { margin: 30px 0; text-align: center; }
.example-box {
    background: linear-gradient(135deg, #E0F7FA, #80DEEA);
    border-left: 5px solid var(--primary-color);
    padding: 20px 25px;
    margin: 20px 0;
    border-radius: 8px;
}
footer {
    text-align: center;
    padding: 40px;
    background: #80DEEA;
    border-top: 2px solid var(--border-color);
    color: var(--text-color);
}
@media (max-width: 768px) {
    header h1 { font-size: 2rem; }
    
    .nav-menu {
        width: 100%;
        min-width: 100%;
        height: auto;
        position: relative;
        flex-direction: row;
        flex-wrap: wrap;
        padding: 10px;
        border-right: none;
        border-bottom: 2px solid var(--border-color);
    }
    .nav-link {
        padding: 8px 15px;
        margin: 4px;
    }
    
    .section { padding: 25px 20px; }
}
    .section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
    
.author-credit {
    font-size: 1rem;
    font-weight: 600;
    margin-top: 15px;
    padding: 8px 20px;
    background: rgba(255, 255, 255, 0.25);
    border-radius: 6px;
    display: inline-block;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    border: 2px solid rgba(255, 255, 255, 0.4);
}
</style>
</head>
<body>
    <header>
        <h1>6. Checkpointing: State Preservation</h1>
        <p class="subtitle">Saving and Restoring AI Training State for Fault Tolerance</p>
        <p class="author-credit">Explained by Naman Adep</p>
    </header>

    <div class="sidebar-wrapper">
    <nav class="nav-menu">
        <a href="#overview" class="nav-link active">Overview</a>
        <a href="#checkpoints" class="nav-link">Checkpoints</a>
        <a href="#process" class="nav-link">Checkpoint Process</a>
        <a href="#restore" class="nav-link">Restore Process</a>
        <a href="#benefits" class="nav-link">Benefits</a>
    </nav>
    <div class="main-content-wrapper">
        <main>
        <section id="overview" class="section">
            <h2>Checkpointing Overview</h2>
            <p>
                Checkpointing is a critical technique for preserving the state of AI training workloads, enabling 
                recovery from failures and allowing training to resume from a saved point rather than starting 
                from the beginning. This process captures the complete state of a training job, including model 
                weights, optimizer state, and training progress, creating a snapshot that can be restored later.
            </p>

            <div class="mermaid">
                graph TD
                    A[Checkpoint System<br/>State Preservation] --> B[Save State<br/>Model Snapshot]
                    B --> C[Store Progress<br/>Model State]
                    B --> D[Store Weights<br/>Learned Parameters]
                    B --> E[Store Optimizer State<br/>Training State]
                    
                    style A fill:#00ACC1
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
                    style E fill:#B2EBF2
            </div>

            <div class="example-box">
                <strong>Why Checkpointing Matters:</strong>
                Training large AI models can take days or weeks. Without checkpointing, a failure means losing 
                all progress and restarting from the beginning. With checkpointing, you can restore the exact 
                state from the last checkpoint and continue training, saving significant time and computational 
                resources. This is essential for production AI training workloads.
            </div>

            <div class="mermaid">
                mindmap
                  root((Checkpointing))
                    Checkpoint Contents
                      Model Weights
                        Learned Parameters
                        All Layers
                      Optimizer State
                        Momentum Buffers
                        Learning Rate Schedule
                      Training State
                        Epoch Number
                        Batch Number
                        Step Count
                      Metrics
                        Training Loss
                        Validation Loss
                        Accuracy
                      Random State
                        RNG Seeds
                        Reproducibility
                    Checkpoint Process
                      Save Frequency
                        Every Epoch
                        Every N Epochs
                        Time-Based
                      Storage Location
                        Local Storage
                        Network Storage
                        Object Storage
                      Checkpoint Types
                        Full Checkpoint
                        Incremental Checkpoint
                        Model-Only Checkpoint
                    Restoration
                      Load Checkpoint
                        Model Weights
                        Optimizer State
                        Training State
                      Resume Training
                        Continue from Epoch
                        Restore Random State
                      Failure Recovery
                        Node Failure
                        Power Outage
                        System Crash
                    Benefits
                      Fault Tolerance
                        Failure Recovery
                        Progress Preservation
                      Experimentation
                        Model Comparison
                        Rollback Capability
                      Resource Savings
                        Time Savings
                        Compute Savings
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Scenario</th>
                        <th>Without Checkpointing</th>
                        <th>With Checkpointing</th>
                        <th>Time Saved</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Failure at Epoch 50/100</strong></td>
                        <td>Restart from Epoch 0</td>
                        <td>Resume from Epoch 50</td>
                        <td>50% of training time</td>
                    </tr>
                    <tr>
                        <td><strong>Power Outage</strong></td>
                        <td>Lose all progress</td>
                        <td>Restore from last checkpoint</td>
                        <td>Days or weeks</td>
                    </tr>
                    <tr>
                        <td><strong>Node Failure</strong></td>
                        <td>Restart entire job</td>
                        <td>Resume on different nodes</td>
                        <td>All previous epochs</td>
                    </tr>
                    <tr>
                        <td><strong>Experimentation</strong></td>
                        <td>Cannot revert changes</td>
                        <td>Restore previous checkpoint</td>
                        <td>Iteration time</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="checkpoints" class="section">
            <h2>Checkpoint Contents</h2>
            <p>
                Checkpoints are complete state snapshots that capture the training state at a specific 
                point. They contain all information needed to restore and continue training from that 
                exact point.
            </p>

            <div class="mermaid">
                graph TB
                    A[Checkpoint File] --> B[Model Weights<br/>All Parameters]
                    A --> C[Optimizer State<br/>Momentum, Learning Rate]
                    A --> D[Training State<br/>Epoch, Batch Number]
                    A --> E[Metrics<br/>Loss, Accuracy]
                    A --> F[Random State<br/>RNG Seeds]
                    
                    B --> G[Complete State<br/>Restore Training]
                    C --> G
                    D --> G
                    E --> G
                    F --> G
                    
                    style A fill:#00ACC1
                    style G fill:#26C6DA
            </div>

            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0;">
                <div class="time-card" style="border-left: 5px solid #00ACC1;">
                    <h3 style="color: #00ACC1; margin-bottom: 15px;">Model Weights</h3>
                    <p><strong>Content:</strong> All learned parameters</p>
                    <p style="margin-top: 10px; font-size: 0.9rem; color: #666;">
                        Millions to billions of values representing what the model has learned.
                    </p>
                </div>

                <div class="time-card" style="border-left: 5px solid #26C6DA;">
                    <h3 style="color: #26C6DA; margin-bottom: 15px;">Optimizer State</h3>
                    <p><strong>Content:</strong> Training optimizer state</p>
                    <p style="margin-top: 10px; font-size: 0.9rem; color: #666;">
                        Momentum buffers, learning rate schedules, and optimizer parameters.
                    </p>
                </div>

                <div class="time-card" style="border-left: 5px solid #4DD0E1;">
                    <h3 style="color: #4DD0E1; margin-bottom: 15px;">Training State</h3>
                    <p><strong>Content:</strong> Epoch and batch number</p>
                    <p style="margin-top: 10px; font-size: 0.9rem; color: #666;">
                        Current position in training to resume from exact point.
                    </p>
                </div>

                <div class="time-card" style="border-left: 5px solid #80DEEA;">
                    <h3 style="color: #80DEEA; margin-bottom: 15px;">Metrics & State</h3>
                    <p><strong>Content:</strong> Loss values and random state</p>
                    <p style="margin-top: 10px; font-size: 0.9rem; color: #666;">
                        Performance metrics and RNG seeds for reproducibility.
                    </p>
                </div>
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Checkpoint Creation] --> B[Save Model Weights]
                    A --> C[Save Optimizer State]
                    A --> D[Save Training State]
                    A --> E[Save Metrics]
                    A --> F[Save Random State]
                    
                    B --> G[Checkpoint File]
                    C --> G
                    D --> G
                    E --> G
                    F --> G
                    
                    G --> H[Storage Location]
                    H --> I[Restore Capability]
                    
                    style A fill:#00ACC1
                    style G fill:#26C6DA
                    style I fill:#4DD0E1
            </div>

            <div class="time-card">
                <h3>What's in a Checkpoint?</h3>
                <div class="mermaid">
                    flowchart LR
                        A[Checkpoint Contents] --> B[Model Weights<br/>All Parameters]
                        A --> C[Optimizer State<br/>Momentum, LR]
                        A --> D[Epoch Number<br/>Training Position]
                        A --> E[Loss Values<br/>Metrics]
                        A --> F[Random State<br/>RNG Seeds]
                        
                        B --> G[Complete Snapshot<br/>Restore Training]
                        C --> G
                        D --> G
                        E --> G
                        F --> G
                        
                        style A fill:#00ACC1
                        style G fill:#26C6DA
                    </div>
            </div>

            <div class="code-example">
# Example: Checkpoint Contents Structure
checkpoint = {
    'epoch': 50,
    'model_state_dict': model.state_dict(),  # All model weights
    'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state
    'loss': current_loss,
    'accuracy': current_accuracy,
    'random_state': torch.get_rng_state(),  # For reproducibility
    'training_args': training_config  # Hyperparameters
}

# Save checkpoint
torch.save(checkpoint, 'checkpoint_epoch_50.pth')

# Load checkpoint
checkpoint = torch.load('checkpoint_epoch_50.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch'] + 1  # Resume from next epoch
            </div>
        </section>

        <section id="process" class="section">
            <h2>Checkpoint Process During Training</h2>
            <p>
                During training, checkpoints are saved at regular intervals (every N epochs or time periods). 
                Each checkpoint captures the current training state, allowing recovery from failures without 
                losing progress.
            </p>

            <div class="mermaid">
                graph TB
                    A[Training Start] --> B[Epoch 1]
                    B -->|Checkpoint| C[Epoch 2]
                    C -->|Checkpoint| D[Epoch 3]
                    D -->|Checkpoint| E[Epoch 4]
                    E -->|Checkpoint| F[Epoch 5]
                    F --> G[Training Complete]
                    
                    B --> H[Checkpoint 1<br/>Saved]
                    C --> I[Checkpoint 2<br/>Saved]
                    D --> J[Checkpoint 3<br/>Saved]
                    
                    style A fill:#00ACC1
                    style G fill:#26C6DA
                    style H fill:#4DD0E1
            </div>

            <div class="mermaid">
                graph LR
                    A[Epoch 1] -->|Save State| B[Checkpoint 1]
                    C[Epoch 2] -->|Save State| D[Checkpoint 2]
                    E[Epoch 3] -->|Save State| F[Checkpoint 3]
                    
                    B --> G[Storage]
                    D --> G
                    F --> G
                    
                    style A fill:#00ACC1
                    style G fill:#26C6DA
            </div>

            <div class="example-box">
                <strong>Checkpoint Frequency:</strong>
                Training progresses through epochs, with each epoch improving model performance. Checkpoints 
                are saved periodically (e.g., every epoch, every N epochs, or every N hours). If training 
                fails, you can restore from the most recent checkpoint and continue, avoiding loss of 
                progress. Regular checkpointing ensures minimal data loss in case of failures.
            </div>
        </section>

        <section id="restore" class="section">
            <h2>Checkpoint Restoration</h2>
            <p>
                Restoring from a checkpoint loads the saved training state and resumes training from that 
                exact point. This includes model weights, optimizer state, and training progress, allowing 
                seamless continuation after failures or interruptions.
            </p>

            <div class="mermaid">
                sequenceDiagram
                    participant Training
                    participant Checkpoint
                    participant Failure
                    participant Restore
                    
                    Training->>Checkpoint: Save progress
                    Training->>Failure: System crash
                    Failure->>Restore: Load checkpoint
                    Restore->>Training: Continue from saved point
                    
                    Note over Training,Restore: Like rewinding time<br/>to a saved moment
            </div>

            <div class="time-card">
                <h3>Why Rewind Works</h3>
                <p>
                    When you restore from a checkpoint, you're going back in time to a saved moment. 
                    Everything is exactly as it was - model weights, optimizer state, everything. 
                    You can then continue training from that point, like nothing happened!
                </p>
            </div>
        </section>

        <section id="benefits" class="section">
            <h2>ðŸ’Ž The Time Benefits: Why It's Worth It</h2>
            <p>
                Checkpointing has a cost (time to save), but the benefits far outweigh it - especially 
                when training fails after days or weeks!
            </p>

            <div class="mermaid">
                graph TD
                    A[Checkpointing Benefits] --> B[Recovery<br/>From Failures]
                    A --> C[Resume Training<br/>Continue Progress]
                    A --> D[Experiment<br/>Try Different Paths]
                    A --> E[Share Progress<br/>Collaborate]
                    
                    style A fill:#00ACC1
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
                    style E fill:#B2EBF2
            </div>

            <div class="example-box">
                <strong>ðŸ’Ž Time Saved:</strong>
                Without checkpointing, a failure after 5 days of training means starting over. With 
                checkpointing, you restore from the last checkpoint (saved 4 hours ago) and continue. 
                This saves 4 days and 20 hours of training time. The checkpoint overhead (time to save) 
                is minimal compared to the time saved by avoiding restarts.
            </div>
        </section>
            </main>

            </div>
</div>

    <footer>
        <p><strong>Checkpointing</strong> - State Preservation for AI Training</p>
        <p>Time travel for AI training - save progress, restore when needed! </p>
    </footer>

    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
                document.querySelector(this.getAttribute('href')).scrollIntoView({ behavior: 'smooth' }
);
            });
        });
        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');
            let current = '';
            sections.forEach(s => {
                if (window.pageYOffset >= s.offsetTop - 100) current = s.getAttribute('id');
            }
);
            navLinks.forEach(l => {
                l.classList.remove('active');
                if (l.getAttribute('href') === `#${current}`) l.classList.add('active');
            });
        });
    </script>
</body>
</html>
