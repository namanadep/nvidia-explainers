<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Infrastructure Architecture: Complete System Design and Components</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
:root {
    --primary-color: #00BCD4;
    --secondary-color: #26C6DA;
    --accent-color: #4DD0E1;
    --bg-color: #E0F7FA;
    --card-bg: #FFFFFF;
    --text-color: #1A1A1A;
    --border-color: #80DEEA;
    --shadow: 0 2px 8px rgba(0, 188, 212, 0.1);
}
body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
    background: var(--bg-color);
    color: var(--text-color);
    line-height: 1.6;
}
header {
    text-align: center;
    padding: 50px 40px;
    background: linear-gradient(135deg, #00BCD4, #26C6DA);
    color: white;
    position: relative;
}
header h1 {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 12px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
}
.subtitle {
    font-size: 1.2rem;
    opacity: 0.95;
    font-weight: 300;
}
.author-credit {
    font-size: 1rem;
    font-weight: 600;
    margin-top: 15px;
    padding: 8px 20px;
    background: rgba(255, 255, 255, 0.25);
    border-radius: 6px;
    display: inline-block;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    border: 2px solid rgba(255, 255, 255, 0.4);
}
.sidebar-wrapper {
    display: flex;
    min-height: calc(100vh - 200px);
}
.nav-menu {
    width: 280px;
    min-width: 280px;
    background: #80DEEA;
    border-right: 2px solid var(--border-color);
    padding: 20px 0;
    position: sticky;
    top: 0;
    height: calc(100vh - 200px);
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 4px;
}
.nav-link {
    color: var(--text-color);
    text-decoration: none;
    padding: 12px 20px;
    margin: 0 10px;
    border-radius: 6px;
    transition: all 0.2s ease;
    font-weight: 500;
    display: block;
}
.nav-link:hover, .nav-link.active {
    background: var(--primary-color);
    color: white;
}
.main-content-wrapper {
    flex: 1;
    width: calc(100% - 280px);
    min-width: 0;
}
.section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
.section h2 {
    font-size: 2.2rem;
    margin-bottom: 20px;
    color: var(--primary-color);
    border-bottom: 3px solid var(--primary-color);
    padding-bottom: 10px;
}
.concept-card {
    background: var(--card-bg);
    padding: 25px;
    border-radius: 12px;
    border: 2px solid var(--border-color);
    margin: 20px 0;
    box-shadow: var(--shadow);
}
.concept-card h3 {
    color: var(--primary-color);
    margin-bottom: 15px;
    font-size: 1.4rem;
}
.comparison-table {
    width: 100%;
    border-collapse: collapse;
    margin: 25px 0;
    background: white;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: var(--shadow);
}
.comparison-table th,
.comparison-table td {
    padding: 15px 20px;
    text-align: left;
    border-bottom: 1px solid var(--border-color);
}
.comparison-table th {
    background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
    color: white;
    font-weight: 600;
}
.comparison-table tr:hover {
    background: var(--bg-color);
}
.code-example {
    background: #263238;
    color: #B0BEC5;
    padding: 20px;
    border-radius: 8px;
    margin: 20px 0;
    font-family: 'Courier New', monospace;
    overflow-x: auto;
    border-left: 4px solid var(--primary-color);
    font-size: 0.9rem;
    line-height: 1.6;
}
.mermaid { margin: 30px 0; text-align: center; }
.example-box {
    background: linear-gradient(135deg, #E0F7FA, #80DEEA);
    border-left: 5px solid var(--primary-color);
    padding: 20px 25px;
    margin: 20px 0;
    border-radius: 8px;
}
.example-box strong {
    color: var(--primary-color);
    display: block;
    margin-bottom: 10px;
    font-size: 1.1rem;
}
footer {
    text-align: center;
    padding: 40px;
    background: #80DEEA;
    border-top: 2px solid var(--border-color);
    color: var(--text-color);
}
@media (max-width: 768px) {
    header h1 { font-size: 2rem; }
    
    .nav-menu {
        width: 100%;
        min-width: 100%;
        height: auto;
        position: relative;
        flex-direction: row;
        flex-wrap: wrap;
        padding: 10px;
        border-right: none;
        border-bottom: 2px solid var(--border-color);
    }
    .nav-link {
        padding: 8px 15px;
        margin: 4px;
    }
    .section { padding: 25px 20px; }
}
    .section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
    </style>
</head>
<body>
    <header>
        <h1>1. AI Infrastructure Architecture</h1>
        <p class="subtitle">Complete System Design and Component Integration</p>
        <p class="author-credit">Explained by Naman Adep</p>
    </header>

    <div class="sidebar-wrapper">
    <nav class="nav-menu">
        <a href="#overview" class="nav-link active">Overview</a>
        <a href="#components" class="nav-link">Components</a>
        <a href="#features" class="nav-link">Features</a>
        <a href="#modules" class="nav-link">Modules</a>
        <a href="#architecture" class="nav-link">Architecture</a>
        <a href="#scaling" class="nav-link">Scaling</a>
    </nav>
    <div class="main-content-wrapper">
        <main>
        <section id="overview" class="section">
            <h2>AI Infrastructure Architecture Overview</h2>
            <p>
                AI infrastructure represents a complete system architecture designed to support artificial 
                intelligence workloads at scale. The architecture defines how all components work together 
                to enable AI training and inference. Understanding this architecture is essential for 
                designing, deploying, and optimizing AI systems. The infrastructure consists of four primary 
                components: compute (GPUs), network (interconnect), storage (data systems), and management 
                (orchestration platforms).
            </p>

            <div class="mermaid">
                graph TD
                    A[AI Infrastructure<br/>Complete System] --> B[Compute<br/>GPU Processing]
                    A --> C[Network<br/>Interconnect]
                    A --> D[Storage<br/>Data Systems]
                    A --> E[Management<br/>Orchestration]
                    
                    B --> F[Training Workloads]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
                    style E fill:#B2EBF2
                    style F fill:#E91E63
            </div>

            <div class="example-box">
                <strong>System Architecture:</strong>
                AI infrastructure is a complete system where compute (GPUs) processes data, network 
                (InfiniBand/Ethernet) enables communication between nodes, storage (Lustre/NFS) provides 
                data access, and management (BCM) orchestrates the entire workflow. All components must 
                work together harmoniously to support efficient AI workloads.
            </div>

            <div class="mermaid">
                mindmap
                  root((AI Infrastructure))
                    Compute
                      GPUs
                        Training
                        Inference
                        Multi-GPU
                      MIG
                      Virtualization
                    Network
                      InfiniBand
                        RDMA
                        Low Latency
                        High Bandwidth
                      Ethernet
                        Standard Networking
                        RoCE
                    Storage
                      Parallel Filesystems
                        Lustre
                        High Throughput
                      Object Storage
                        S3
                        Archive
                      Checkpointing
                    Management
                      BCM
                        Orchestration
                        Monitoring
                      Auto-Scaling
                      Job Scheduling
            </div>

            <div class="mermaid">
                graph TB
                    A[Distributed Training<br/>64 GPUs] --> B[Compute<br/>8 Nodes Ã— 8 GPUs<br/>Process Batches]
                    A --> C[Network<br/>InfiniBand<br/>All-Reduce Sync]
                    A --> D[Storage<br/>Lustre<br/>10+ TB/s]
                    A --> E[Management<br/>BCM<br/>Orchestration]
                    
                    B --> F[Training Success<br/>All Components Essential]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
            </div>

            <div class="mermaid">
                flowchart LR
                    A[Without Network] --> B[Gradient Sync<br/>Bottleneck]
                    C[Without Storage] --> D[GPUs Wait<br/>For Data]
                    E[Without Management] --> F[Jobs Fail<br/>No Recovery]
                    
                    G[With All Components] --> H[Efficient Training<br/>High Performance]
                    
                    style A fill:#FF6B6B
                    style C fill:#FF6B6B
                    style E fill:#FF6B6B
                    style G fill:#00BCD4
                    style H fill:#E91E63
            </div>
        </section>

        <section id="components" class="section">
            <h2>Core Components</h2>
            <p>
                The infrastructure consists of four core components that work together. Each component 
                has a specific role, and they integrate to form a complete system. Understanding how 
                these components interact is crucial for designing effective AI infrastructure.
            </p>

            <div class="mermaid">
                graph TB
                    subgraph "Component Integration"
                        A[Compute<br/>GPUs] ---|Requires| B[Network<br/>Interconnect]
                        C[Storage<br/>Data Systems] ---|Accessed via| B
                        A ---|Reads from| C
                        D[Management<br/>Orchestration] ---|Controls| A
                        D ---|Manages| B
                        D ---|Manages| C
                    end
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
            </div>

            <div class="mermaid">
                flowchart LR
                    A[Compute<br/>GPUs] <-->|Process & Sync| B[Network<br/>Interconnect]
                    C[Storage<br/>Data Systems] -->|Data Flow| B
                    B -->|Deliver Data| A
                    D[Management<br/>Orchestration] -->|Controls| A
                    D -->|Manages| B
                    D -->|Manages| C
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
            </div>

            <div class="concept-card">
                <h3>Component Roles and Interactions</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Compute + Network:</strong> GPUs process data, network moves data between nodes. Essential for distributed training where gradients must be synchronized across multiple GPUs.</li>
                    <li><strong>Storage + Network:</strong> Storage holds training data, network provides access. Data flows from storage through network to compute nodes for processing.</li>
                    <li><strong>Compute + Storage:</strong> Compute nodes need data, storage provides it. Forms the core data processing pipeline where models read training data.</li>
                    <li><strong>Management + All:</strong> Management orchestrates all components. Coordinates resource allocation, job scheduling, and system monitoring.</li>
                </ul>
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Distributed Training Job] --> B[Compute<br/>GPUs Process Batches]
                    A --> C[Network<br/>InfiniBand All-Reduce]
                    A --> D[Storage<br/>Lustre High Throughput]
                    A --> E[Management<br/>BCM Orchestration]
                    
                    B --> F[All Components<br/>Work Together]
                    C --> F
                    D --> F
                    E --> F
                    
                    F --> G[Efficient Training<br/>High Performance]
                    
                    style A fill:#00BCD4
                    style G fill:#E91E63
            </div>

            <div class="mermaid">
                sequenceDiagram
                    participant User
                    participant BCM as Management
                    participant Storage
                    participant Network
                    participant Compute as GPUs
                    
                    User->>BCM: Submit Training Job
                    BCM->>Compute: Allocate GPUs
                    BCM->>Storage: Request Data Access
                    Storage->>Network: Stream Training Data
                    Network->>Compute: Deliver Data to GPUs
                    Compute->>Compute: Process Batches
                    Compute->>Network: Exchange Gradients
                    Network->>Compute: Synchronize Gradients
                    Compute->>BCM: Report Progress
                    BCM->>User: Job Status Updates
                    
                    Note over Compute,Network: All components<br/>work together
            </div>

            <div class="mermaid">
                graph LR
                    A[Training Job] --> B[Compute<br/>GPUs Process Data]
                    A --> C[Network<br/>Sync Gradients]
                    A --> D[Storage<br/>Provide Data]
                    A --> E[Management<br/>Orchestrate]
                    
                    B --> F[Completed<br/>Training]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
            </div>
        </section>

        <section id="features" class="section">
            <h2>Key Features</h2>
            <p>
                Infrastructure features are specific capabilities that determine what the system can do. 
                These features enable high-performance AI workloads through optimized compute, network, 
                storage, and management capabilities.
            </p>

            <div class="mermaid">
                graph TD
                    A[Infrastructure Features] --> B[GPU Acceleration<br/>Tensor Cores, MIG]
                    A --> C[RDMA Networking<br/>Zero-Copy, Low Latency]
                    A --> D[Parallel Filesystems<br/>High Throughput]
                    A --> E[Auto-Scaling<br/>Dynamic Resource Allocation]
                    
                    B --> F[High Performance]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Infrastructure Features] --> B[Compute Features]
                    A --> C[Network Features]
                    A --> D[Storage Features]
                    A --> E[Management Features]
                    
                    B --> B1[GPU Acceleration]
                    B --> B2[Tensor Cores]
                    B --> B3[MIG]
                    B --> B4[Virtualization]
                    
                    C --> C1[RDMA]
                    C --> C2[Zero-Copy]
                    C --> C3[Low Latency]
                    C --> C4[High Bandwidth]
                    
                    D --> D1[Parallel FS]
                    D --> D2[High Throughput]
                    D --> D3[Checkpointing]
                    D --> D4[Data Locality]
                    
                    E --> E1[Auto-Scaling]
                    E --> E2[Job Scheduling]
                    E --> E3[Monitoring]
                    E --> E4[Health Checks]
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
                    style E fill:#B2EBF2
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Feature Categories] --> B[Compute Features<br/>GPU, Tensor Cores, MIG]
                    A --> C[Network Features<br/>RDMA, Zero-Copy, Low Latency]
                    A --> D[Storage Features<br/>Lustre, High Throughput, Checkpointing]
                    A --> E[Management Features<br/>Auto-Scaling, Scheduling, Monitoring]
                    
                    B --> F[Complete Feature Set<br/>High Performance]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
                </div>

            <div class="mermaid">
                flowchart LR
                    A[Feature Impact] --> B[RDMA<br/>Zero-Copy<br/>Low Latency]
                    A --> C[Parallel FS<br/>High Throughput<br/>Fast Data Loading]
                    A --> D[Tensor Cores<br/>Matrix Ops<br/>2-4x Faster]
                    A --> E[MIG<br/>Partitioning<br/>Better Utilization]
                    
                    B --> F[Optimized Performance<br/>All Features Work Together]
                    C --> F
                    D --> F
                    E --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
                </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>Without Feature</th>
                        <th>With Feature</th>
                        <th>Performance Impact</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>RDMA Networking</strong></td>
                        <td>CPU copies data, high latency</td>
                        <td>Direct memory access, zero-copy</td>
                        <td>10-100x lower latency, reduced CPU usage</td>
                    </tr>
                    <tr>
                        <td><strong>Parallel Filesystem</strong></td>
                        <td>Single storage server bottleneck</td>
                        <td>Multiple OSTs, parallel I/O</td>
                        <td>10-100x higher throughput</td>
                    </tr>
                    <tr>
                        <td><strong>Tensor Cores</strong></td>
                        <td>Standard FP32 operations</td>
                        <td>Mixed precision (FP16/BF16)</td>
                        <td>2-4x faster training</td>
                    </tr>
                    <tr>
                        <td><strong>MIG</strong></td>
                        <td>Full GPU per workload</td>
                        <td>GPU partitioning, multi-tenancy</td>
                        <td>Better resource utilization</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="modules" class="section">
            <h2>Infrastructure Modules</h2>
            <p>
                Infrastructure modules are major subsystems that group related components and capabilities 
                together. Each module handles a specific aspect of the infrastructure, and modules work 
                together to provide complete functionality.
            </p>

            <div class="mermaid">
                graph TB
                    subgraph "Module 1: Compute"
                        C1[GPU Systems] --> C2[MIG Support]
                        C1 --> C3[Virtualization]
                        C1 --> C4[Multi-GPU]
                        C1 --> C5[Tensor Cores]
                    end
                    
                    subgraph "Module 2: Network"
                        N1[InfiniBand] --> N2[Ethernet]
                        N1 --> N3[UFM Management]
                        N1 --> N4[RDMA]
                        N1 --> N5[RoCE Support]
                    end
                    
                    subgraph "Module 3: Storage"
                        S1[Lustre FS] --> S2[NFS]
                        S1 --> S3[Object Storage]
                        S1 --> S4[Checkpointing]
                        S1 --> S5[Data Tiering]
                    end
                    
                    subgraph "Module 4: Management"
                        M1[BCM] --> M2[Monitoring]
                        M1 --> M3[Orchestration]
                        M1 --> M4[Auto-Scaling]
                        M1 --> M5[Job Scheduling]
                    end
                    
                    style C1 fill:#00BCD4
                    style N1 fill:#26C6DA
                    style S1 fill:#4DD0E1
                    style M1 fill:#80DEEA
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Infrastructure Modules] --> B[Compute Module<br/>GPUs, MIG, Virtualization]
                    A --> C[Network Module<br/>InfiniBand, Ethernet, UFM]
                    A --> D[Storage Module<br/>Lustre, NFS, Object Storage]
                    A --> E[Management Module<br/>BCM, Monitoring, Orchestration]
                    
                    B --> B1[GPU Systems<br/>MIG Partitioning<br/>Multi-Tenancy<br/>Multi-GPU Scaling]
                    C --> C1[High-Performance Interconnect<br/>Standard Networking<br/>Network Management<br/>Zero-Copy RDMA]
                    D --> D1[Parallel Filesystem<br/>Standard File Access<br/>Large Datasets<br/>Checkpointing]
                    E --> E1[Cluster Management<br/>System Health<br/>Workload Management<br/>Dynamic Scaling]
                    
                    B1 --> F[Complete Infrastructure<br/>All Modules Work Together]
                    C1 --> F
                    D1 --> F
                    E1 --> F
                    
                    style A fill:#00BCD4
                    style F fill:#E91E63
                </div>

            <div class="mermaid">
                sequenceDiagram
                    participant Workload
                    participant Compute as Compute Module<br/>GPUs
                    participant Network as Network Module<br/>InfiniBand
                    participant Storage as Storage Module<br/>Lustre
                    participant Management as Management Module<br/>BCM
                    
                    Workload->>Management: Submit Training Job
                    Management->>Compute: Allocate GPUs
                    Management->>Network: Configure Interconnect
                    Management->>Storage: Mount Filesystems
                    
                    Compute->>Storage: Request Training Data
                    Storage->>Network: Stream Data
                    Network->>Compute: Deliver Data
                    Compute->>Compute: Process Batches
                    Compute->>Network: Exchange Gradients
                    Network->>Compute: All-Reduce Sync
                    Compute->>Management: Report Progress
                    
                    Note over Compute,Management: Seamless Module<br/>Interaction
                </div>

            <div class="mermaid">
                flowchart TD
                    A[Workload Request] --> B[Management Module<br/>BCM]
                    B --> C[Compute Module<br/>Allocate GPUs]
                    B --> D[Network Module<br/>Configure Interconnect]
                    B --> E[Storage Module<br/>Mount Filesystems]
                    
                    C --> F[Training Execution]
                    D --> F
                    E --> F
                    
                    F --> G[Compute: Process Data]
                    F --> H[Network: Sync Gradients]
                    F --> I[Storage: Load Data]
                    
                    G --> J[Completed Job]
                    H --> J
                    I --> J
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style J fill:#E91E63
            </div>
        </section>

        <section id="architecture" class="section">
            <h2>Complete Architecture Stack</h2>
            <p>
                The complete infrastructure stack consists of multiple layers, from hardware to applications. 
                Each layer builds upon the previous one, creating a comprehensive system for AI workloads.
            </p>

            <div class="mermaid">
                graph TB
                    subgraph "Application Layer"
                        E1[AI Frameworks<br/>PyTorch, TensorFlow]
                        E2[Training Scripts]
                        E3[Model Definitions]
                    end
                    
                    subgraph "Management Layer"
                        F1[Orchestration<br/>Kubernetes, Slurm]
                        F2[Monitoring<br/>Metrics, Health]
                        F3[BCM<br/>Cluster Management]
                    end
                    
                    subgraph "Runtime Layer"
                        D1[CUDA Runtime]
                        D2[cuDNN]
                        D3[cuBLAS]
                    end
                    
                    subgraph "System Software Layer"
                        C1[Linux OS]
                        C2[NVIDIA Drivers]
                        C3[Firmware]
                    end
                    
                    subgraph "Hardware Layer"
                        B1[GPUs<br/>Compute]
                        B2[InfiniBand<br/>Network]
                        B3[SSDs<br/>Storage]
                    end
                    
                    E1 --> D1
                    E2 --> D1
                    E3 --> D1
                    D1 --> C2
                    D2 --> C2
                    D3 --> C2
                    C2 --> B1
                    C1 --> B1
                    C3 --> B1
                    F1 --> C1
                    F2 --> C1
                    F3 --> C1
                    
                    style E1 fill:#B2EBF2
                    style D1 fill:#80DEEA
                    style C2 fill:#4DD0E1
                    style B1 fill:#26C6DA
                    style F1 fill:#E0F7FA
            </div>

            <div class="mermaid">
                flowchart TD
                    A[Architecture Stack] --> B[Application Layer<br/>TensorFlow, PyTorch]
                    A --> C[Runtime Layer<br/>CUDA, cuDNN, cuBLAS]
                    A --> D[System Software<br/>Linux, Drivers, Firmware]
                    A --> E[Hardware Layer<br/>GPUs, Network, Storage]
                    A --> F[Management Layer<br/>Kubernetes, Slurm, BCM]
                    
                    B --> G[Complete Stack<br/>All Layers Integrated]
                    C --> G
                    D --> G
                    E --> G
                    F --> G
                    
                    style A fill:#00BCD4
                    style G fill:#E91E63
                </div>

            <div class="mermaid">
                flowchart TD
                    A[Optimal Architecture] --> B[Hardware<br/>Foundation]
                    B --> C[System Software<br/>Hardware Access]
                    C --> D[Runtime Libraries<br/>Optimize Operations]
                    D --> E[Applications<br/>AI Workloads]
                    E --> F[Management<br/>Efficient Operation]
                    
                    B --> G[Complete Stack<br/>Optimized Performance]
                    C --> G
                    D --> G
                    E --> G
                    F --> G
                    
                    style A fill:#00BCD4
                    style G fill:#E91E63
                </div>

            <div class="mermaid">
                sequenceDiagram
                    participant App as Application Layer
                    participant Runtime as Runtime Layer
                    participant System as System Software
                    participant HW as Hardware Layer
                    participant Mgt as Management Layer
                    
                    App->>Runtime: Request GPU Operations
                    Runtime->>System: Access GPU Drivers
                    System->>HW: Initialize GPU Hardware
                    HW-->>System: Hardware Ready
                    System-->>Runtime: Driver Access Granted
                    Runtime->>HW: Execute CUDA Kernels
                    HW-->>Runtime: Results Returned
                    Runtime-->>App: Operations Complete
                    Mgt->>HW: Monitor Health
                    Mgt->>System: Track Metrics
                    Mgt->>Runtime: Resource Allocation
                    
                    Note over App,HW: Complete Stack<br/>Working Together
            </div>

            <div class="concept-card">
                <h3>Layer-by-Layer Example</h3>
                <p>Here's how each layer contributes to a training workload:</p>
                <ol style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Hardware Layer:</strong> GPUs provide compute, InfiniBand provides network, SSDs provide storage</li>
                    <li><strong>System Software:</strong> Linux OS, NVIDIA drivers enable GPU access, firmware initializes hardware</li>
                    <li><strong>Runtime Layer:</strong> CUDA runtime executes kernels, cuDNN accelerates convolutions, cuBLAS accelerates matrix ops</li>
                    <li><strong>Application Layer:</strong> PyTorch/TensorFlow frameworks, training scripts, model definitions</li>
                    <li><strong>Management Layer:</strong> Kubernetes/Slurm schedules jobs, monitoring tracks metrics, BCM manages cluster</li>
                </ol>
                <p style="margin-top: 15px;">
                    Each layer must be properly configured. For example, outdated drivers prevent GPU access, 
                    missing cuDNN slows training, and poor scheduling causes resource contention.
                </p>
            </div>
        </section>

        <section id="scaling" class="section">
            <h2>Scaling Infrastructure</h2>
            <p>
                Scaling infrastructure involves growing the system to handle larger workloads. The system 
                evolves from small deployments to large clusters, with each stage adding capabilities and 
                optimizing performance. Understanding scaling strategies helps plan infrastructure growth 
                effectively.
            </p>

            <div class="mermaid">
                graph TB
                    A[Small Deployment<br/>1-4 Nodes<br/>Single Rack] -->|Add Compute| B[Medium Deployment<br/>8-16 Nodes<br/>Multiple Racks]
                    B -->|Add Network| C[Large Deployment<br/>32+ Nodes<br/>Full Cluster]
                    C -->|Optimize| D[Optimized Deployment<br/>Tuned Configuration<br/>Maximum Efficiency]
                    
                    A -->|Scaling Factors| E[More GPUs]
                    B -->|Scaling Factors| F[Better Network Topology]
                    C -->|Scaling Factors| G[Optimized Storage]
                    D -->|Scaling Factors| H[All Components Optimized]
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Deployment Stage</th>
                        <th>Infrastructure Size</th>
                        <th>Capabilities</th>
                        <th>Use Case</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Small Deployment</strong></td>
                        <td>1-4 nodes, single rack</td>
                        <td>Basic training, single-user workloads</td>
                        <td>Development, prototyping, small models</td>
                    </tr>
                    <tr>
                        <td><strong>Medium Deployment</strong></td>
                        <td>8-16 nodes, multiple racks</td>
                        <td>Distributed training, multi-user support</td>
                        <td>Production training, research, medium models</td>
                    </tr>
                    <tr>
                        <td><strong>Large Deployment</strong></td>
                        <td>32+ nodes, full cluster</td>
                        <td>Large-scale training, enterprise workloads</td>
                        <td>Enterprise AI, large language models, HPC</td>
                    </tr>
                    <tr>
                        <td><strong>Optimized Deployment</strong></td>
                        <td>Tuned configuration</td>
                        <td>Maximum efficiency, all features enabled</td>
                        <td>Optimal performance, cost-effective operations</td>
                    </tr>
                </tbody>
            </table>

            <div class="example-box">
                <strong>Scaling Strategy:</strong>
                Infrastructure scales through stages: A small deployment (1-4 nodes) grows to medium 
                (8-16 nodes) by adding more compute nodes. It grows to large (32+ nodes) by adding 
                network infrastructure and storage systems. Finally, it becomes optimized through 
                performance tuning and configuration optimization. Understanding scaling stages helps 
                plan infrastructure growth and budget effectively.
            </div>

            <div class="mermaid">
                graph LR
                    A[Stage 1<br/>Small<br/>4 Nodes<br/>32 GPUs] -->|Add Nodes| B[Stage 2<br/>Medium<br/>16 Nodes<br/>128 GPUs]
                    B -->|Add Network| C[Stage 3<br/>Large<br/>64 Nodes<br/>512 GPUs]
                    C -->|Optimize| D[Stage 4<br/>Optimized<br/>Tuned Config<br/>Max Efficiency]
                    
                    A --> A1[Ethernet 10Gb/s<br/>Local NVMe]
                    B --> B1[InfiniBand HDR 200Gb/s<br/>Lustre FS]
                    C --> C1[InfiniBand NDR 400Gb/s<br/>Lustre Tiered]
                    D --> D1[Optimized Topology<br/>Balanced Resources]
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
            </div>

            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Stage</th>
                        <th>Nodes</th>
                        <th>Total GPUs</th>
                        <th>Network</th>
                        <th>Storage</th>
                        <th>Bandwidth</th>
                        <th>Use Case</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Stage 1: Small</strong></td>
                        <td>4</td>
                        <td>32 GPUs</td>
                        <td>Ethernet 10Gb/s</td>
                        <td>Local NVMe</td>
                        <td>40 Gb/s total</td>
                        <td>Development, prototyping</td>
                    </tr>
                    <tr>
                        <td><strong>Stage 2: Medium</strong></td>
                        <td>16</td>
                        <td>128 GPUs</td>
                        <td>InfiniBand HDR 200Gb/s</td>
                        <td>Lustre parallel FS</td>
                        <td>3.2 Tb/s total</td>
                        <td>Production training, research</td>
                    </tr>
                    <tr>
                        <td><strong>Stage 3: Large</strong></td>
                        <td>64</td>
                        <td>512 GPUs</td>
                        <td>InfiniBand NDR 400Gb/s</td>
                        <td>Lustre with tiering</td>
                        <td>25.6 Tb/s total</td>
                        <td>Enterprise AI, LLMs</td>
                    </tr>
                    <tr>
                        <td><strong>Stage 4: Optimized</strong></td>
                        <td>Tuned</td>
                        <td>Balanced</td>
                        <td>Optimized topology</td>
                        <td>Tiered & optimized</td>
                        <td>Maximum efficiency</td>
                        <td>Peak performance</td>
                    </tr>
                </tbody>
            </table>

            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0;">
                <div class="concept-card" style="border-left: 5px solid #00BCD4;">
                    <h3 style="color: #00BCD4; margin-bottom: 15px;">Stage 1: Small Deployment</h3>
                    <p><strong>Configuration:</strong></p>
                    <ul style="margin-top: 10px; padding-left: 20px; line-height: 1.8;">
                        <li><strong>Nodes:</strong> 4</li>
                        <li><strong>GPUs:</strong> 32 (8 per node)</li>
                        <li><strong>Network:</strong> Ethernet 10Gb/s</li>
                        <li><strong>Storage:</strong> Local NVMe</li>
                    </ul>
                    <p style="margin-top: 15px; font-size: 0.9rem; color: #666;">
                        Ideal for development, prototyping, and small model training. Low initial investment with standard networking.
                    </p>
                </div>

                <div class="concept-card" style="border-left: 5px solid #26C6DA;">
                    <h3 style="color: #26C6DA; margin-bottom: 15px;">Stage 2: Medium Deployment</h3>
                    <p><strong>Configuration:</strong></p>
                    <ul style="margin-top: 10px; padding-left: 20px; line-height: 1.8;">
                        <li><strong>Nodes:</strong> 16</li>
                        <li><strong>GPUs:</strong> 128 (8 per node)</li>
                        <li><strong>Network:</strong> InfiniBand HDR 200Gb/s</li>
                        <li><strong>Storage:</strong> Lustre parallel FS</li>
                    </ul>
                    <p style="margin-top: 15px; font-size: 0.9rem; color: #666;">
                        Upgraded network enables distributed training. Shared storage supports multi-user workloads and larger datasets.
                    </p>
                </div>

                <div class="concept-card" style="border-left: 5px solid #4DD0E1;">
                    <h3 style="color: #4DD0E1; margin-bottom: 15px;">Stage 3: Large Deployment</h3>
                    <p><strong>Configuration:</strong></p>
                    <ul style="margin-top: 10px; padding-left: 20px; line-height: 1.8;">
                        <li><strong>Nodes:</strong> 64</li>
                        <li><strong>GPUs:</strong> 512 (8 per node)</li>
                        <li><strong>Network:</strong> InfiniBand NDR 400Gb/s</li>
                        <li><strong>Storage:</strong> Lustre with tiering</li>
                    </ul>
                    <p style="margin-top: 15px; font-size: 0.9rem; color: #666;">
                        High-performance network supports large-scale distributed training. Tiered storage optimizes cost and performance.
                    </p>
                </div>

                <div class="concept-card" style="border-left: 5px solid #80DEEA;">
                    <h3 style="color: #80DEEA; margin-bottom: 15px;">Stage 4: Optimized Deployment</h3>
                    <p><strong>Configuration:</strong></p>
                    <ul style="margin-top: 10px; padding-left: 20px; line-height: 1.8;">
                        <li><strong>Topology:</strong> Optimized</li>
                        <li><strong>Resources:</strong> Balanced</li>
                        <li><strong>Network:</strong> Optimized topology</li>
                        <li><strong>Storage:</strong> Tiered & optimized</li>
                    </ul>
                    <p style="margin-top: 15px; font-size: 0.9rem; color: #666;">
                        All components tuned for maximum efficiency. Network topology optimized, storage tiered, compute balanced for peak performance.
                    </p>
                </div>
            </div>

            <div class="code-example">
# Example: Infrastructure Scaling Configuration
# Stage 1: Small Deployment (1-4 nodes)
nodes = 4
gpus_per_node = 8
total_gpus = nodes * gpus_per_node  # 32 GPUs
network = "Ethernet 10Gb/s"
storage = "Local NVMe"

# Stage 2: Medium Deployment (8-16 nodes)
nodes = 16
gpus_per_node = 8
total_gpus = nodes * gpus_per_node  # 128 GPUs
network = "InfiniBand HDR 200Gb/s"  # Upgraded network
storage = "Lustre parallel filesystem"  # Shared storage

# Stage 3: Large Deployment (32+ nodes)
nodes = 64
gpus_per_node = 8
total_gpus = nodes * gpus_per_node  # 512 GPUs
network = "InfiniBand NDR 400Gb/s"  # High-performance network
storage = "Lustre with data tiering"  # Optimized storage

# Stage 4: Optimized Deployment
# All components tuned for maximum efficiency
# Network topology optimized, storage tiered, compute balanced
            </div>

            <div class="mermaid">
                graph TD
                    A[Infrastructure Scaling] --> B[Stage 1: Small<br/>4 Nodes, 32 GPUs]
                    A --> C[Stage 2: Medium<br/>16 Nodes, 128 GPUs]
                    A --> D[Stage 3: Large<br/>64 Nodes, 512 GPUs]
                    A --> E[Stage 4: Optimized<br/>Tuned Configuration]
                    
                    B --> B1[Ethernet 10Gb/s<br/>Local NVMe<br/>Development]
                    C --> C1[InfiniBand HDR 200Gb/s<br/>Lustre FS<br/>Production]
                    D --> D1[InfiniBand NDR 400Gb/s<br/>Lustre Tiered<br/>Enterprise]
                    E --> E1[Optimized Topology<br/>Balanced Resources<br/>Peak Performance]
                    
                    style A fill:#00BCD4
                    style B fill:#26C6DA
                    style C fill:#4DD0E1
                    style D fill:#80DEEA
                    style E fill:#B2EBF2
            </div>
        </section>
        </main>
    </div>
</div>

    <footer>
        <p><strong>AI Infrastructure Architecture</strong> - Complete System Design</p>
        <p>Understanding infrastructure components, features, modules, and scaling strategies</p>
    </footer>

    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
                document.querySelector(this.getAttribute('href')).scrollIntoView({ behavior: 'smooth' }
