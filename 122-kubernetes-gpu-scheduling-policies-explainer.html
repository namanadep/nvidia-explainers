<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>122. Kubernetes GPU Scheduling Policies: GPU Resource Scheduling in Kubernetes</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
:root {
    --primary-color: #1565C0;
    --secondary-color: #1976D2;
    --accent-color: #1E88E5;
    --bg-color: #E3F2FD;
    --card-bg: #FFFFFF;
    --text-color: #1A1A1A;
    --border-color: #90CAF9;
    --shadow: 0 2px 8px rgba(21, 101, 192, 0.1);
}
body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
    background: var(--bg-color);
    color: var(--text-color);
    line-height: 1.6;
}
header {
    text-align: center;
    padding: 50px 40px;
    background: linear-gradient(135deg, #1565C0, #1976D2);
    color: white;
    position: relative;
}
header h1 {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 12px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
}
.subtitle {
    font-size: 1.2rem;
    opacity: 0.95;
    font-weight: 300;
}
.author-credit {
    font-size: 1rem;
    font-weight: 600;
    margin-top: 15px;
    padding: 8px 20px;
    background: rgba(255, 255, 255, 0.25);
    border-radius: 6px;
    display: inline-block;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    border: 2px solid rgba(255, 255, 255, 0.4);
}

.sidebar-wrapper {
    display: flex;
    min-height: calc(100vh - 200px);
}
.nav-menu {
    width: 280px;
    min-width: 280px;
    background: #80DEEA;
    border-right: 2px solid var(--border-color);
    padding: 20px 0;
    position: sticky;
    top: 0;
    height: calc(100vh - 200px);
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 4px;
}
.nav-link {
    color: var(--text-color);
    text-decoration: none;
    padding: 12px 20px;
    margin: 0 10px;
    border-radius: 6px;
    transition: all 0.2s ease;
    font-weight: 500;
    display: block;
}
.nav-link:hover, .nav-link.active {
    background: var(--primary-color);
    color: white;
}
.main-content-wrapper {
    flex: 1;
    width: calc(100% - 280px);
    min-width: 0;
}

.section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
.section h2 {
    font-size: 2.2rem;
    margin-bottom: 20px;
    color: var(--primary-color);
    border-bottom: 3px solid var(--primary-color);
    padding-bottom: 10px;
}
.section h3 {
    font-size: 1.6rem;
    margin: 25px 0 15px;
    color: var(--secondary-color);
}
.section p {
    margin-bottom: 18px;
    font-size: 1.05rem;
    line-height: 1.8;
}
.policy-card {
    background: var(--card-bg);
    padding: 25px;
    border-radius: 12px;
    border-left: 5px solid var(--primary-color);
    margin: 20px 0;
    box-shadow: var(--shadow);
}
.policy-card h3 {
    color: var(--primary-color);
    margin-bottom: 15px;
    font-size: 1.4rem;
}
.concept-card {
    background: var(--card-bg);
    padding: 25px;
    border-radius: 12px;
    border: 2px solid var(--border-color);
    margin: 20px 0;
    box-shadow: var(--shadow);
}
.concept-card h3 {
    color: var(--primary-color);
    margin-bottom: 15px;
    font-size: 1.4rem;
}
.mermaid { margin: 30px 0; text-align: center; }
.example-box {
    background: linear-gradient(135deg, #E3F2FD, #90CAF9);
    border-left: 5px solid var(--primary-color);
    padding: 20px 25px;
    margin: 20px 0;
    border-radius: 8px;
}
.example-box strong {
    color: var(--primary-color);
    display: block;
    margin-bottom: 10px;
    font-size: 1.1rem;
}
code {
    background: #F5F5F5;
    padding: 2px 8px;
    border-radius: 4px;
    font-family: 'Courier New', monospace;
    color: #D32F2F;
}
.command-box {
    background: #263238;
    color: #1E88E5;
    padding: 20px;
    border-radius: 8px;
    margin: 15px 0;
    font-family: 'Courier New', monospace;
    overflow-x: auto;
}
footer {
    text-align: center;
    padding: 40px;
    background: #90CAF9;
    border-top: 2px solid var(--border-color);
    color: var(--text-color);
}
@media (max-width: 768px) {
    header h1 { font-size: 2rem; }
    
    .nav-menu {
        width: 100%;
        min-width: 100%;
        height: auto;
        position: relative;
        flex-direction: row;
        flex-wrap: wrap;
        padding: 10px;
        border-right: none;
        border-bottom: 2px solid var(--border-color);
    }
    .nav-link {
        padding: 8px 15px;
        margin: 4px;
    }
    
    .section { padding: 25px 20px; }
}
    .section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
    </style>
</head>
<body>
    <header>
        <h1>122. Kubernetes GPU Scheduling Policies</h1>
        <p class="subtitle">GPU Resource Scheduling and Allocation in Kubernetes</p>
        <p class="author-credit">Explained by Naman Adep</p>
    </header>

    <div class="sidebar-wrapper">
    <nav class="nav-menu">
        <a href="#overview" class="nav-link active">Overview</a>
        <a href="#scheduling-algorithms" class="nav-link">Scheduling Algorithms</a>
        <a href="#resource-quotas" class="nav-link">Resource Quotas</a>
        <a href="#affinity" class="nav-link">Affinity Rules</a>
        <a href="#gpu-sharing" class="nav-link">GPU Sharing</a>
        <a href="#best-practices" class="nav-link">Best Practices</a>
    </nav>
    <div class="main-content-wrapper">
        <main>
        <section id="overview" class="section">
            <h2>Kubernetes GPU Scheduling Overview</h2>
            <p>
                Kubernetes GPU scheduling policies control how GPU resources are allocated to pods. Effective scheduling 
                policies ensure fair resource allocation, optimal GPU utilization, and proper workload placement. 
                Scheduling includes resource quotas, affinity/anti-affinity rules, and GPU sharing strategies. 
                Understanding GPU scheduling policies enables efficient GPU resource management in Kubernetes clusters.
            </p>

            <div class="mermaid">
                graph TD
                    A[GPU Scheduling] --> B[Scheduler]
                    A --> C[Resource Quotas]
                    A --> D[Affinity Rules]
                    A --> E[GPU Sharing]
                    B --> F[Filter Nodes]
                    B --> G[Score Nodes]
                    B --> H[Bind Pod]
                    C --> I[Namespace Limits]
                    C --> J[User Limits]
                    D --> K[Node Affinity]
                    D --> L[Pod Affinity]
                    E --> M[Time-Slicing]
                    E --> N[MIG]
                    
                    style A fill:#1565C0
                    style B fill:#1976D2
                    style E fill:#1E88E5
            </div>

            <div class="example-box">
                <strong>Scheduling Policy Impact:</strong>
                Effective GPU scheduling policies can improve GPU utilization from 50% to 80%+, reduce pod wait times, 
                and ensure fair resource allocation. Proper quotas prevent resource exhaustion, and affinity rules 
                optimize workload placement.
            </div>

            <div class="mermaid">
                mindmap
                  root((GPU Scheduling Policies))
                    Scheduling Algorithms
                      Filter Phase
                      Score Phase
                      Bind Phase
                    Resource Quotas
                      Namespace Quotas
                      User Quotas
                      GPU Limits
                    Affinity Rules
                      Node Affinity
                      Pod Affinity
                      Anti-Affinity
                    GPU Sharing
                      Time-Slicing
                      MIG Support
                      Resource Allocation
            </div>
        </section>

        <section id="scheduling-algorithms" class="section">
            <h2>GPU Scheduling Algorithms</h2>
            <p>
                Kubernetes scheduler uses a two-phase algorithm to schedule pods with GPU requests: filtering and 
                scoring. Understanding the scheduling algorithm helps optimize GPU allocation.
            </p>

            <div class="policy-card">
                <h3>Scheduling Phases</h3>
                <p>Kubernetes scheduler operates in three phases:</p>
                
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Filter Phase:</strong> Filters out nodes that cannot satisfy pod requirements</li>
                    <li><strong>Score Phase:</strong> Scores remaining nodes based on various factors</li>
                    <li><strong>Bind Phase:</strong> Binds pod to highest-scoring node</li>
                </ul>

                <div class="mermaid">
                    flowchart TD
                        A[Pod with GPU Request] --> B[Filter Phase]
                        B --> C{Node Has GPU?}
                        C -->|No| D[Filter Out]
                        C -->|Yes| E{GPU Available?}
                        E -->|No| D
                        E -->|Yes| F[Score Phase]
                        F --> G[Calculate Scores]
                        G --> H[Select Best Node]
                        H --> I[Bind Phase]
                        I --> J[Pod Scheduled]
                        
                        style A fill:#1565C0
                        style J fill:#4CAF50
                        style C fill:#FF9800
                        style E fill:#FF9800
                </div>
            </div>

            <div class="policy-card">
                <h3>GPU Resource Filtering</h3>
                <p>Filter nodes based on GPU availability:</p>
                
                <p style="margin-top: 20px;"><strong>Filter Criteria:</strong></p>
                <ul style="margin-top: 10px; padding-left: 20px; line-height: 2;">
                    <li>Node has GPU resources available</li>
                    <li>GPU count meets pod requirements</li>
                    <li>GPU type matches requirements (if specified)</li>
                    <li>Node taints/tolerations match</li>
                </ul>
            </div>
        </section>

        <section id="resource-quotas" class="section">
            <h2>Resource Quotas</h2>
            <p>
                Resource quotas limit GPU resource consumption per namespace or user. Quotas prevent resource exhaustion 
                and ensure fair resource allocation.
            </p>

            <div class="concept-card">
                <h3>Namespace Resource Quotas</h3>
                <p>Set GPU quotas for namespaces:</p>
                
                <p style="margin-top: 20px;"><strong>Resource Quota Example:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: ResourceQuota
metadata:
  name: gpu-quota
  namespace: ai-training
spec:
  hard:
    requests.nvidia.com/gpu: "8"
    limits.nvidia.com/gpu: "16"
    requests.memory: "128Gi"
    limits.memory: "256Gi"
    requests.cpu: "32"
    limits.cpu: "64"
                </div>

                <p style="margin-top: 20px;"><strong>Check Quota Usage:</strong></p>
                <div class="command-box">
# View resource quota
kubectl get resourcequota -n ai-training

# Describe quota details
kubectl describe resourcequota gpu-quota -n ai-training
                </div>
            </div>

            <div class="concept-card">
                <h3>Limit Ranges</h3>
                <p>Set default limits and requests:</p>
                
                <p style="margin-top: 20px;"><strong>LimitRange Example:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: LimitRange
metadata:
  name: gpu-limits
  namespace: ai-training
spec:
  limits:
  - default:
      nvidia.com/gpu: "1"
      memory: "16Gi"
      cpu: "4"
    defaultRequest:
      nvidia.com/gpu: "1"
      memory: "16Gi"
      cpu: "4"
    type: Container
                </div>
            </div>
        </section>

        <section id="affinity" class="section">
            <h2>Affinity and Anti-Affinity Rules</h2>
            <p>
                Affinity and anti-affinity rules control pod placement relative to nodes or other pods. Use affinity 
                rules to optimize GPU workload placement.
            </p>

            <div class="policy-card">
                <h3>Node Affinity</h3>
                <p>Schedule pods on specific nodes:</p>
                
                <p style="margin-top: 20px;"><strong>Node Affinity Example:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: accelerator
            operator: In
            values:
            - nvidia-tesla-v100
            - nvidia-tesla-a100
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: gpu-model
            operator: In
            values:
            - a100
  containers:
  - name: gpu-container
    image: nvidia/cuda:12.0.0-base-ubuntu22.04
    resources:
      limits:
        nvidia.com/gpu: 1
                </div>
            </div>

            <div class="policy-card">
                <h3>Pod Affinity and Anti-Affinity</h3>
                <p>Control pod co-location:</p>
                
                <p style="margin-top: 20px;"><strong>Pod Anti-Affinity Example:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - training
        topologyKey: kubernetes.io/hostname
  containers:
  - name: gpu-container
    image: nvidia/cuda:12.0.0-base-ubuntu22.04
    resources:
      limits:
        nvidia.com/gpu: 1
                </div>
            </div>

            <div class="mermaid">
                flowchart LR
                    A[Pod Scheduling] --> B{Node Affinity?}
                    B -->|Required| C[Must Match]
                    B -->|Preferred| D[Prefer Match]
                    B -->|None| E[Any Node]
                    C --> F{GPU Available?}
                    D --> F
                    E --> F
                    F -->|Yes| G[Schedule Pod]
                    F -->|No| H[Pod Pending]
                    
                    style A fill:#1565C0
                    style G fill:#4CAF50
                    style F fill:#FF9800
            </div>
        </section>

        <section id="gpu-sharing" class="section">
            <h2>GPU Sharing Strategies</h2>
            <p>
                GPU sharing enables multiple pods to share GPU resources. Sharing strategies include time-slicing and 
                MIG support.
            </p>

            <div class="concept-card">
                <h3>Time-Slicing Configuration</h3>
                <p>Configure GPU time-slicing for sharing:</p>
                
                <p style="margin-top: 20px;"><strong>Time-Slicing ConfigMap:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: kube-system
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 4
                </div>

                <p style="margin-top: 20px;"><strong>Pod with Time-Sliced GPU:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: Pod
metadata:
  name: shared-gpu-pod
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:12.0.0-base-ubuntu22.04
    resources:
      limits:
        nvidia.com/gpu: 1
      requests:
        nvidia.com/gpu: 1
                </div>
            </div>

            <div class="concept-card">
                <h3>MIG Support</h3>
                <p>Use MIG instances for GPU sharing:</p>
                
                <p style="margin-top: 20px;"><strong>MIG Resource Request:</strong></p>
                <div class="command-box">
apiVersion: v1
kind: Pod
metadata:
  name: mig-pod
spec:
  containers:
  - name: mig-container
    image: nvidia/cuda:12.0.0-base-ubuntu22.04
    resources:
      limits:
        nvidia.com/mig-1g.10gb: 1
      requests:
        nvidia.com/mig-1g.10gb: 1
                </div>
            </div>
        </section>

        <section id="best-practices" class="section">
            <h2>GPU Scheduling Best Practices</h2>
            <p>
                Follow best practices for effective GPU scheduling in Kubernetes.
            </p>

            <div class="concept-card">
                <h3>Scheduling Best Practices</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li>Set appropriate resource requests and limits</li>
                    <li>Use resource quotas to prevent exhaustion</li>
                    <li>Configure node affinity for GPU type selection</li>
                    <li>Use pod anti-affinity to distribute workloads</li>
                    <li>Enable GPU sharing when appropriate</li>
                    <li>Monitor GPU utilization and scheduling</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Resource Management Best Practices</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li>Set GPU requests equal to limits for guaranteed allocation</li>
                    <li>Use namespaces to organize GPU workloads</li>
                    <li>Implement resource quotas per namespace</li>
                    <li>Monitor quota usage</li>
                    <li>Adjust quotas based on usage patterns</li>
                </ul>
            </div>

            <div class="example-box">
                <strong>GPU Scheduling Checklist:</strong>
                1. Configure device plugin for GPU discovery<br>
                2. Set resource quotas for namespaces<br>
                3. Configure limit ranges<br>
                4. Set node affinity for GPU selection<br>
                5. Configure pod affinity/anti-affinity<br>
                6. Enable GPU sharing if needed<br>
                7. Monitor GPU scheduling metrics<br>
                8. Optimize based on metrics<br>
                9. Document scheduling policies<br>
                10. Review and adjust regularly
            </div>
        </section>
            </main>

            </div>
</div>

    <footer>
        <p>Kubernetes GPU Scheduling Policies | GPU Resource Scheduling in Kubernetes</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                const targetSection = document.querySelector(targetId);
                
                document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
                
                targetSection.scrollIntoView({ behavior: 'smooth', block: 'start' }
);
            });
        });

        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (window.pageYOffset >= sectionTop - 100) {
                    current = section.getAttribute('id');
                }

            });

            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${current}`) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>
