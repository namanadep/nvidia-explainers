<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>93. Kubernetes GPU Operations: Orchestrating GPU Workloads</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
* { margin: 0; padding: 0; box-sizing: border-box; }
:root {
    --primary-color: #5D4037;
    --secondary-color: #6D4C41;
    --accent-color: #8D6E63;
    --bg-color: #EFEBE9;
    --card-bg: #FFFFFF;
    --text-color: #1A1A1A;
    --border-color: #BCAAA4;
    --shadow: 0 2px 8px rgba(93, 64, 55, 0.1);
}
body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
    background: var(--bg-color);
    color: var(--text-color);
    line-height: 1.6;
}
header {
    text-align: center;
    padding: 50px 40px;
    background: linear-gradient(135deg, #5D4037, #6D4C41);
    color: white;
}
header h1 {
    font-size: 2.5rem;
    font-weight: 700;
    margin-bottom: 12px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
}
.subtitle {
    font-size: 1.2rem;
    opacity: 0.95;
    font-weight: 300;
}
.author-credit {
    font-size: 1rem;
    font-weight: 600;
    margin-top: 15px;
    padding: 8px 20px;
    background: rgba(255, 255, 255, 0.25);
    border-radius: 6px;
    display: inline-block;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    border: 2px solid rgba(255, 255, 255, 0.4);
}

.sidebar-wrapper {
    display: flex;
    min-height: calc(100vh - 200px);
}
.nav-menu {
    width: 280px;
    min-width: 280px;
    background: #80DEEA;
    border-right: 2px solid var(--border-color);
    padding: 20px 0;
    position: sticky;
    top: 0;
    height: calc(100vh - 200px);
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 4px;
}
.nav-link {
    color: var(--text-color);
    text-decoration: none;
    padding: 12px 20px;
    margin: 0 10px;
    border-radius: 6px;
    transition: all 0.2s ease;
    font-weight: 500;
    display: block;
}
.nav-link:hover, .nav-link.active {
    background: var(--primary-color);
    color: white;
}
.main-content-wrapper {
    flex: 1;
    width: calc(100% - 280px);
    min-width: 0;
}

.section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
.section h2 {
    font-size: 2.2rem;
    margin-bottom: 20px;
    color: var(--primary-color);
    border-bottom: 3px solid var(--primary-color);
    padding-bottom: 10px;
}
.concept-card {
    background: var(--card-bg);
    padding: 25px;
    border-radius: 12px;
    border: 2px solid var(--border-color);
    margin: 20px 0;
    box-shadow: var(--shadow);
}
.concept-card h3 {
    color: var(--primary-color);
    margin-bottom: 15px;
    font-size: 1.4rem;
}
.command-box {
    background: #263238;
    color: #BCAAA4;
    padding: 20px;
    border-radius: 8px;
    margin: 15px 0;
    font-family: 'Courier New', monospace;
    overflow-x: auto;
}
.mermaid { margin: 30px 0; text-align: center; }
.example-box {
    background: linear-gradient(135deg, #EFEBE9, #D7CCC8);
    border-left: 5px solid var(--primary-color);
    padding: 20px 25px;
    margin: 20px 0;
    border-radius: 8px;
}
.example-box strong {
    color: var(--primary-color);
    display: block;
    margin-bottom: 10px;
    font-size: 1.1rem;
}
footer {
    text-align: center;
    padding: 40px;
    background: #BCAAA4;
    border-top: 2px solid var(--border-color);
    color: var(--text-color);
}
@media (max-width: 768px) {
    header h1 { font-size: 2rem; }
    
    .nav-menu {
        width: 100%;
        min-width: 100%;
        height: auto;
        position: relative;
        flex-direction: row;
        flex-wrap: wrap;
        padding: 10px;
        border-right: none;
        border-bottom: 2px solid var(--border-color);
    }
    .nav-link {
        padding: 8px 15px;
        margin: 4px;
    }
    
    .section { padding: 25px 20px; }
}
    .section {
    padding: 40px;
    min-height: calc(100vh - 200px);
    border-bottom: 1px solid var(--border-color);
    max-width: 100%;
}
    </style>
</head>
<body>
    <header>
        <h1>93. Kubernetes GPU Operations</h1>
        <p class="subtitle">Orchestrating GPU Workloads in Kubernetes</p>
        <p class="author-credit">Explained by Naman Adep</p>
    </header>

    <div class="sidebar-wrapper">
    <nav class="nav-menu">
        <a href="#overview" class="nav-link active">Overview</a>
        <a href="#resource-management" class="nav-link">Resource Management</a>
        <a href="#scheduling" class="nav-link">Scheduling</a>
        <a href="#device-plugins" class="nav-link">Device Plugins</a>
        <a href="#multi-gpu" class="nav-link">Multi-GPU Support</a>
    </nav>
    <div class="main-content-wrapper">
        <main>
        <section id="overview" class="section">
            <h2>Kubernetes GPU Operations Overview</h2>
            <p>
                Kubernetes GPU operations enable orchestration of GPU workloads in Kubernetes clusters, providing GPU 
                resource management, scheduling, and multi-GPU support. Kubernetes manages GPU resources through device 
                plugins, schedules GPU workloads based on availability, and supports various GPU allocation strategies. 
                Understanding Kubernetes GPU operations enables efficient deployment and management of GPU-accelerated 
                applications in containerized environments, providing scalability, resource isolation, and operational 
                efficiency for AI workloads.
            </p>

            <div class="mermaid">
                graph TD
                    A[Kubernetes Cluster] --> B[GPU Nodes]
                    B --> C[Device Plugin]
                    C --> D[GPU Resources]
                    D --> E[Pod Scheduling]
                    
                    style A fill:#5D4037
                    style B fill:#6D4C41
                    style E fill:#8D6E63
            </div>

            <div class="example-box">
                <strong>GPU Orchestration:</strong>
                Kubernetes GPU operations manage GPU resources for containerized workloads. Kubernetes discovers GPU 
                resources through device plugins, schedules workloads to available GPUs based on resource requests, 
                and manages GPU allocation to pods. Kubernetes ensures efficient GPU utilization across the cluster 
                by matching workload requirements with available GPU resources.
            </div>

            <div class="mermaid">
                mindmap
                  root((Kubernetes GPU Operations))
                    Resource Management
                      Device Plugins
                      GPU Discovery
                      Resource Allocation
                    Scheduling
                      Workload Scheduling
                      GPU Matching
                      Multi-GPU Support
                    Benefits
                      Scalability
                      Resource Isolation
                      Operational Efficiency
            </div>
        </section>

        <section id="resource-management" class="section">
            <h2>GPU Resource Management</h2>
            <p>
                Kubernetes manages GPU resources through device plugins, exposing GPUs as schedulable resources and 
                enabling GPU allocation to pods.
            </p>

            <div class="concept-card">
                <h3>Resource Model</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>GPU Resources:</strong> GPUs as Kubernetes resources</li>
                    <li><strong>Resource Requests:</strong> Pod GPU requests</li>
                    <li><strong>Resource Limits:</strong> Pod GPU limits</li>
                    <li><strong>Allocation:</strong> GPU allocation to pods</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Resource Specification</h3>
                <div class="command-box">
apiVersion: v1<br>
kind: Pod<br>
spec:<br>
  containers:<br>
  - name: gpu-container<br>
    image: nvidia/cuda:11.8.0-runtime<br>
    resources:<br>
      limits:<br>
        nvidia.com/gpu: 1<br>
      requests:<br>
        nvidia.com/gpu: 1
                </div>
            </div>

            <div class="concept-card">
                <h3>Resource Allocation</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Exclusive:</strong> Exclusive GPU allocation</li>
                    <li><strong>Shared:</strong> Shared GPU allocation</li>
                    <li><strong>MIG:</strong> MIG-based allocation</li>
                    <li><strong>Time-Sharing:</strong> Time-sharing allocation</li>
                </ul>
            </div>
        </section>

        <section id="scheduling" class="section">
            <h2>GPU Scheduling</h2>
            <p>
                Kubernetes schedules GPU workloads based on GPU availability, resource requests, and scheduling policies, 
                ensuring efficient GPU utilization.
            </p>

            <div class="mermaid">
                graph LR
                    A[Pod Request] --> B[Kubernetes Scheduler]
                    B --> C{GPU Available?}
                    C -->|Yes| D[Schedule Pod]
                    C -->|No| E[Queue Pod]
                    
                    style A fill:#5D4037
                    style B fill:#6D4C41
                    style D fill:#8D6E63
            </div>

            <div class="concept-card">
                <h3>Scheduling Process</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Resource Discovery:</strong> Discover GPU resources</li>
                    <li><strong>Request Matching:</strong> Match pod requests to GPUs</li>
                    <li><strong>Scheduling Decision:</strong> Make scheduling decisions</li>
                    <li><strong>Pod Placement:</strong> Place pods on GPU nodes</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Scheduling Policies</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Default:</strong> Default Kubernetes scheduling</li>
                    <li><strong>Custom Schedulers:</strong> Custom GPU schedulers</li>
                    <li><strong>Affinity:</strong> Node affinity for GPUs</li>
                    <li><strong>Anti-Affinity:</strong> Pod anti-affinity</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Scheduling Optimization</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Bin Packing:</strong> Efficient GPU packing</li>
                    <li><strong>Load Balancing:</strong> Balance GPU load</li>
                    <li><strong>Priority:</strong> Priority-based scheduling</li>
                    <li><strong>Preemption:</strong> Preemption for high-priority pods</li>
                </ul>
            </div>
        </section>

        <section id="device-plugins" class="section">
            <h2>Device Plugins</h2>
            <p>
                Kubernetes device plugins enable GPU resource discovery and allocation, providing the interface between 
                Kubernetes and GPU hardware.
            </p>

            <div class="concept-card">
                <h3>NVIDIA Device Plugin</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>GPU Discovery:</strong> Discover GPU resources</li>
                    <li><strong>Resource Registration:</strong> Register GPUs with Kubernetes</li>
                    <li><strong>Allocation:</strong> Allocate GPUs to pods</li>
                    <li><strong>Health Monitoring:</strong> Monitor GPU health</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Device Plugin Features</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Multi-GPU:</strong> Support multiple GPUs</li>
                    <li><strong>MIG:</strong> MIG support</li>
                    <li><strong>Time-Sharing:</strong> Time-sharing support</li>
                    <li><strong>Monitoring:</strong> GPU monitoring</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Device Plugin Deployment</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>DaemonSet:</strong> Deploy as DaemonSet</li>
                    <li><strong>Node-Level:</strong> One plugin per node</li>
                    <li><strong>Configuration:</strong> Configure plugin settings</li>
                    <li><strong>Updates:</strong> Update device plugins</li>
                </ul>
            </div>
        </section>

        <section id="multi-gpu" class="section">
            <h2>Multi-GPU Support</h2>
            <p>
                Kubernetes supports multi-GPU workloads, enabling pods to request multiple GPUs and supporting distributed 
                training scenarios.
            </p>

            <div class="concept-card">
                <h3>Multi-GPU Allocation</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Multiple GPUs:</strong> Request multiple GPUs</li>
                    <li><strong>GPU Selection:</strong> GPU selection strategies</li>
                    <li><strong>Topology:</strong> GPU topology awareness</li>
                    <li><strong>NVLink:</strong> NVLink-aware allocation</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Distributed Training</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Multi-Node:</strong> Multi-node GPU training</li>
                    <li><strong>Pod Groups:</strong> Pod group scheduling</li>
                    <li><strong>Communication:</strong> Inter-pod communication</li>
                    <li><strong>Coordination:</strong> Training coordination</li>
                </ul>
            </div>

            <div class="concept-card">
                <h3>Best Practices</h3>
                <ul style="margin-top: 15px; padding-left: 20px; line-height: 2;">
                    <li><strong>Resource Requests:</strong> Specify GPU requirements</li>
                    <li><strong>Node Selection:</strong> Use node selectors</li>
                    <li><strong>Topology:</strong> Consider GPU topology</li>
                    <li><strong>Monitoring:</strong> Monitor GPU usage</li>
                </ul>
            </div>

            <div class="example-box">
                <strong>Kubernetes GPU Operations:</strong>
                Deploy GPU workloads in Kubernetes by configuring device plugins, specifying GPU resource requests, 
                leveraging GPU scheduling, and supporting multi-GPU scenarios. Use device plugins for GPU discovery, 
                configure resource requests and limits, optimize scheduling policies, and support distributed training. 
                Kubernetes GPU operations enable efficient orchestration of GPU workloads in containerized environments.
            </div>
        </section>
            </main>

            </div>
</div>

    <footer>
        <p>Kubernetes GPU Operations Guide | Orchestrating GPU Workloads</p>
    </footer>

    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
        
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                const targetSection = document.querySelector(targetId);
                if (targetSection) {
                    targetSection.scrollIntoView({ behavior: 'smooth' }
);
                    document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                    this.classList.add('active');
                }

            });
        });

        const sections = document.querySelectorAll('.section');
        const navLinks = document.querySelectorAll('.nav-link');
        
        window.addEventListener('scroll', () => {
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                if (pageYOffset >= sectionTop - 200) {
                    current = section.getAttribute('id');
                }

            });
            
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${current}`) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>
